{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc858c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dhyut\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow\n",
    "from tensorflow.keras.layers import Conv2D,\\\n",
    "\tMaxPool2D, Conv2DTranspose, Input, Activation,\\\n",
    "\tConcatenate, CenterCrop\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.initializers import HeNormal\n",
    "from tensorflow.keras.optimizers import schedules, Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a16f6cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset - Training and Testing Sets\n",
    "\n",
    "train_address_input = r\"C:\\Users\\dhyut\\SEM 7\\DL Project\\RITE_Dataset\\training\\images\"\n",
    "train_address_labels = r\"C:\\Users\\dhyut\\SEM 7\\DL Project\\RITE_Dataset\\training\\av\"\n",
    "train_address_vessel = r\"C:\\Users\\dhyut\\SEM 7\\DL Project\\RITE_Dataset\\training\\vessel\"\n",
    "train_data_ip = []\n",
    "train_data_av = []\n",
    "train_data_vessel = []\n",
    "img_names_train = []\n",
    "\n",
    "test_address_input = r\"C:\\Users\\dhyut\\SEM 7\\DL Project\\RITE_Dataset\\test\\images\"\n",
    "test_address_labels = r\"C:\\Users\\dhyut\\SEM 7\\DL Project\\RITE_Dataset\\test\\av\"\n",
    "test_address_vessel = r\"C:\\Users\\dhyut\\SEM 7\\DL Project\\RITE_Dataset\\test\\vessel\"\n",
    "test_data_ip = []\n",
    "test_data_av = []\n",
    "test_data_vessel = []\n",
    "img_names_test = []\n",
    "\n",
    "for img in os.listdir(train_address_input):\n",
    "    img_name = os.path.join(train_address_input, img)\n",
    "    img_names_train.append(img_name)\n",
    "    img = cv2.imread(img_name)\n",
    "#     img = cv2.resize(img, (360, 360))\n",
    "    train_data_ip.append(img)\n",
    "    \n",
    "for img in os.listdir(train_address_labels):\n",
    "    img_name = os.path.join(train_address_labels, img)\n",
    "    img = cv2.imread(img_name)\n",
    "#     img = cv2.resize(img, (360, 360))\n",
    "    train_data_av.append(img)\n",
    "\n",
    "for img in os.listdir(train_address_vessel):\n",
    "    img_name = os.path.join(train_address_vessel, img)\n",
    "    img = cv2.imread(img_name)\n",
    "#     img = cv2.resize(img, (360, 360))\n",
    "    train_data_vessel.append(img)\n",
    "    \n",
    "for img in os.listdir(test_address_input):\n",
    "    img_name = os.path.join(test_address_input, img)\n",
    "    img = cv2.imread(img_name)\n",
    "#     img = cv2.resize(img, (360, 360))\n",
    "    test_data_ip.append(img)\n",
    "    img_names_test.append(img_name)\n",
    "    \n",
    "for img in os.listdir(test_address_labels):\n",
    "    img_name = os.path.join(test_address_labels, img)\n",
    "    img = cv2.imread(img_name)\n",
    "#     img = cv2.resize(img, (360, 360))\n",
    "    test_data_av.append(img)\n",
    "\n",
    "for img in os.listdir(test_address_vessel):\n",
    "    img_name = os.path.join(test_address_vessel, img)\n",
    "    img = cv2.imread(img_name)\n",
    "#     img = cv2.resize(img, (360, 360))\n",
    "    test_data_vessel.append(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "679002c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.Series(train_data_ip)\n",
    "df.to_csv(\"demo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "addee5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\tU-NET CONFIGURATION\n",
    "'''\n",
    "def configuration():\n",
    "\t''' Get configuration. '''\n",
    "\n",
    "\treturn dict(\n",
    "\t\tdata_train_prc = 80,\n",
    "\t\tdata_val_prc = 90,\n",
    "\t\tdata_test_prc = 100,\n",
    "\t\tnum_filters_start = 64,\n",
    "\t\tnum_unet_blocks = 3,\n",
    "\t\tnum_filters_end = 3,\n",
    "\t\tinput_width = 100,\n",
    "\t\tinput_height = 100,\n",
    "\t\tmask_width = 60,\n",
    "\t\tmask_height = 60,\n",
    "\t\tinput_dim = 3,\n",
    "\t\toptimizer = Adam,\n",
    "\t\tloss = SparseCategoricalCrossentropy,\n",
    "\t\tinitializer = HeNormal(),\n",
    "\t\tbatch_size = 50,\n",
    "\t\tbuffer_size = 50,\n",
    "\t\tnum_epochs = 25,\n",
    "\t\tmetrics = ['accuracy'],\n",
    "\t\tdataset_path = os.path.join(os.getcwd(), 'data'),\n",
    "\t\tclass_weights = tensorflow.constant([1.0, 1.0, 2.0]),\n",
    "\t\tvalidation_sub_splits = 5,\n",
    "\t\tlr_schedule_percentages = [0.2, 0.5, 0.8],\n",
    "\t\tlr_schedule_values = [3e-4, 1e-4, 1e-5, 1e-6],\n",
    "\t\tlr_schedule_class = schedules.PiecewiseConstantDecay\n",
    "\t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e76af58",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\tU-NET BUILDING BLOCKS\n",
    "'''\n",
    "\n",
    "def conv_block(x, filters, last_block):\n",
    "\t'''\n",
    "\t\tU-Net convolutional block.\n",
    "\t\tUsed for downsampling in the contracting path.\n",
    "\t'''\n",
    "\tconfig = configuration()\n",
    "\n",
    "\t# First Conv segment\n",
    "\tx = Conv2D(filters, (3, 3),\\\n",
    "\t\tkernel_initializer=config.get(\"initializer\"))(x)\n",
    "\tx = Activation(\"relu\")(x)\n",
    "\n",
    "\t# Second Conv segment\n",
    "\tx = Conv2D(filters, (3, 3),\\\n",
    "\t\tkernel_initializer=config.get(\"initializer\"))(x)\n",
    "\tx = Activation(\"relu\")(x)\n",
    "\n",
    "\t# Keep Conv output for skip input\n",
    "\tskip_input = x\n",
    "\n",
    "\t# Apply pooling if not last block\n",
    "\tif not last_block:\n",
    "\t\tx = MaxPool2D((2, 2), strides=(2,2))(x)\n",
    "\n",
    "\treturn x, skip_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d24332a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_number_of_filters(block_number):\n",
    "\t'''\n",
    "\t\tCompute the number of filters for a specific\n",
    "\t\tU-Net block given its position in the contracting path.\n",
    "\t'''\n",
    "\treturn configuration().get(\"num_filters_start\") * (2 ** block_number)\n",
    "\n",
    "def contracting_path(x):\n",
    "\t'''\n",
    "\t\tU-Net contracting path.\n",
    "\t\tInitializes multiple convolutional blocks for \n",
    "\t\tdownsampling.\n",
    "\t'''\n",
    "\tconfig = configuration()\n",
    "\n",
    "\t# Compute the number of feature map filters per block\n",
    "\tnum_filters = [compute_number_of_filters(index)\\\n",
    "\t\t\tfor index in range(config.get(\"num_unet_blocks\"))]\n",
    "\n",
    "\t# Create container for the skip input Tensors\n",
    "\tskip_inputs = []\n",
    "\n",
    "\t# Pass input x through all convolutional blocks and\n",
    "\t# add skip input Tensor to skip_inputs if not last block\n",
    "\tfor index, block_num_filters in enumerate(num_filters):\n",
    "\n",
    "\t\tlast_block = index == len(num_filters)-1\n",
    "\t\tx, skip_input = conv_block(x, block_num_filters,\\\n",
    "\t\t\tlast_block)\n",
    "\n",
    "\t\tif not last_block:\n",
    "\t\t\tskip_inputs.append(skip_input)\n",
    "\n",
    "\treturn x, skip_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4885b12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upconv_block(x, filters, skip_input, last_block = False):\n",
    "\t'''\n",
    "\t\tU-Net upsampling block.\n",
    "\t\tUsed for upsampling in the expansive path.\n",
    "\t'''\n",
    "\tconfig = configuration()\n",
    "\n",
    "\t# Perform upsampling\n",
    "\tx = Conv2DTranspose(filters//2, (2, 2), strides=(2, 2),\\\n",
    "\t\tkernel_initializer=config.get(\"initializer\"))(x)\n",
    "\tshp = x.shape\n",
    "\n",
    "\t# Crop the skip input, keep the center\n",
    "\tcropped_skip_input = CenterCrop(height = x.shape[1],\\\n",
    "\t\twidth = x.shape[2])(skip_input)\n",
    "\n",
    "\t# Concatenate skip input with x\n",
    "\tconcat_input = Concatenate(axis=-1)([cropped_skip_input, x])\n",
    "\n",
    "\t# First Conv segment\n",
    "\tx = Conv2D(filters//2, (3, 3),\n",
    "\t\tkernel_initializer=config.get(\"initializer\"))(concat_input)\n",
    "\tx = Activation(\"relu\")(x)\n",
    "\n",
    "\t# Second Conv segment\n",
    "\tx = Conv2D(filters//2, (3, 3),\n",
    "\t\tkernel_initializer=config.get(\"initializer\"))(x)\n",
    "\tx = Activation(\"relu\")(x)\n",
    "\n",
    "\t# Prepare output if last block\n",
    "\tif last_block:\n",
    "\t\tx = Conv2D(config.get(\"num_filters_end\"), (1, 1),\n",
    "\t\t\tkernel_initializer=config.get(\"initializer\"))(x)\n",
    "\n",
    "\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ab6cdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expansive_path(x, skip_inputs):\n",
    "\t'''\n",
    "\t\tU-Net expansive path.\n",
    "\t\tInitializes multiple upsampling blocks for upsampling.\n",
    "\t'''\n",
    "\tnum_filters = [compute_number_of_filters(index)\\\n",
    "\t\t\tfor index in range(configuration()\\\n",
    "\t\t\t\t.get(\"num_unet_blocks\")-1, 0, -1)]\n",
    "\n",
    "\tskip_max_index = len(skip_inputs) - 1\n",
    "\n",
    "\tfor index, block_num_filters in enumerate(num_filters):\n",
    "\t\tskip_index = skip_max_index - index\n",
    "\t\tlast_block = index == len(num_filters)-1\n",
    "\t\tx = upconv_block(x, block_num_filters,\\\n",
    "\t\t\tskip_inputs[skip_index], last_block)\n",
    "\n",
    "\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2001113c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_unet():\n",
    "\t''' Construct U-Net. '''\n",
    "\tconfig = configuration()\n",
    "\tinput_shape = (config.get(\"input_height\"),\\\n",
    "\t\tconfig.get(\"input_width\"), config.get(\"input_dim\"))\n",
    "\n",
    "\t# Construct input layer\n",
    "\tinput_data = Input(shape=input_shape)\n",
    "\n",
    "\t# Construct Contracting path\n",
    "\tcontracted_data, skip_inputs = contracting_path(input_data)\n",
    "\n",
    "\t# Construct Expansive path\n",
    "\texpanded_data = expansive_path(contracted_data, skip_inputs)\n",
    "\n",
    "\t# Define model\n",
    "\tmodel = Model(input_data, expanded_data, name=\"U-Net\")\n",
    "\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "065a4220",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\tU-NET TRAINING PROCESS BUILDING BLOCKS\n",
    "'''\n",
    "\n",
    "def init_model(steps_per_epoch):\n",
    "\t'''\n",
    "\t\tInitialize a U-Net model.\n",
    "\t'''\n",
    "\tconfig = configuration()\n",
    "\tmodel = build_unet()\n",
    "\n",
    "\t# Retrieve compilation input\n",
    "\tloss_init = config.get(\"loss\")(from_logits=True)\n",
    "\tmetrics = config.get(\"metrics\")\n",
    "\tnum_epochs = config.get(\"num_epochs\")\n",
    "\n",
    "\t# Construct LR schedule\n",
    "\tboundaries = [int(num_epochs * percentage * steps_per_epoch)\\\n",
    "\t\tfor percentage in config.get(\"lr_schedule_percentages\")]\n",
    "\tlr_schedule = config.get(\"lr_schedule_class\")(boundaries, config.get(\"lr_schedule_values\"))\n",
    "\n",
    "\t# Init optimizer\n",
    "\toptimizer_init = config.get(\"optimizer\")(learning_rate = lr_schedule)\n",
    "\n",
    "\t# Compile the model\n",
    "\tmodel.compile(loss=loss_init, optimizer=optimizer_init, metrics=metrics)\n",
    "\n",
    "\t# Plot the model\n",
    "\tplot_model(model, to_file=\"unet.png\")\n",
    "\n",
    "\t# Print model summary\n",
    "\tmodel.summary()\n",
    "\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0216397",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "\t'''\tReturn dataset with info. '''\n",
    "\tconfig = configuration()\n",
    "\n",
    "\t# Retrieve percentages\n",
    "\ttrain = config.get(\"data_train_prc\")\n",
    "\tval = config.get(\"data_val_prc\")\n",
    "\ttest = config.get(\"data_test_prc\")\n",
    "\n",
    "\t# Redefine splits over full dataset\n",
    "\tsplits = [f'train[:{train}%]+test[:{train}%]',\\\n",
    "\t\tf'train[{train}%:{val}%]+test[{train}%:{val}%]',\\\n",
    "\t\tf'train[{val}%:{test}%]+test[{val}%:{test}%]']\n",
    "\n",
    "\t# Return data\n",
    "\treturn tfds.load('oxford_iiit_pet:3.*.*', split=splits, data_dir=configuration()\\\n",
    "\t\t.get(\"dataset_path\"), with_info=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bab02b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_sample(input_image, input_mask):\n",
    "\t''' Normalize input image and mask class. '''\n",
    "\t# Cast image to float32 and divide by 255\n",
    "\tinput_image = tensorflow.cast(input_image, tensorflow.float32) / 255.0\n",
    "\n",
    "  # Bring classes into range [0, 2]\n",
    "\tinput_mask -= 1\n",
    "\n",
    "\treturn input_image, input_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "123ec961",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sample(data_sample):\n",
    "\t''' Resize and normalize dataset samples. '''\n",
    "\tconfig = configuration()\n",
    "\n",
    "\t# Resize image\n",
    "\tinput_image = tensorflow.image.resize(data_sample['image'],\\\n",
    "  \t(config.get(\"input_width\"), config.get(\"input_height\")))\n",
    "\n",
    "  # Resize mask\n",
    "\tinput_mask = tensorflow.image.resize(data_sample['segmentation_mask'],\\\n",
    "  \t(config.get(\"mask_width\"), config.get(\"mask_height\")))\n",
    "\n",
    "  # Normalize input image and mask\n",
    "\tinput_image, input_mask = normalize_sample(input_image, input_mask)\n",
    "\n",
    "\treturn input_image, input_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb2caf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augmentation(inputs, labels):\n",
    "\t''' Perform data augmentation. '''\n",
    "\t# Use the same seed for deterministic randomness over both inputs and labels.\n",
    "\tseed = 36\n",
    "\n",
    "  # Feed data through layers\n",
    "\tinputs = tensorflow.image.random_flip_left_right(inputs, seed=seed)\n",
    "\tinputs = tensorflow.image.random_flip_up_down(inputs, seed=seed)\n",
    "\tlabels = tensorflow.image.random_flip_left_right(labels, seed=seed)\n",
    "\tlabels = tensorflow.image.random_flip_up_down(labels, seed=seed)\n",
    "\n",
    "\treturn inputs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88a09cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sample_weights(image, mask):\n",
    "\t''' Compute sample weights for the image given class. '''\n",
    "\t# Compute relative weight of class\n",
    "\tclass_weights = configuration().get(\"class_weights\")\n",
    "\tclass_weights = class_weights/tensorflow.reduce_sum(class_weights)\n",
    "\n",
    "  # Compute same-shaped Tensor as mask with sample weights per\n",
    "  # mask element. \n",
    "\tsample_weights = tensorflow.gather(class_weights,indices=\\\n",
    "  \ttensorflow.cast(mask, tensorflow.int32))\n",
    "\n",
    "\treturn image, mask, sample_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4d3ba6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(data, dataset_type, dataset_info):\n",
    "\t''' Fully preprocess dataset given dataset type. '''\n",
    "\tconfig = configuration()\n",
    "\tbatch_size = config.get(\"batch_size\")\n",
    "\tbuffer_size = config.get(\"buffer_size\")\n",
    "\n",
    "\t# Preprocess data given dataset type.\n",
    "\tif dataset_type == \"train\" or dataset_type == \"val\":\n",
    "\t\t# 1. Perform preprocessing\n",
    "\t\t# 2. Cache dataset for improved performance\n",
    "\t\t# 3. Shuffle dataset\n",
    "\t\t# 4. Generate batches\n",
    "\t\t# 5. Repeat\n",
    "\t\t# 6. Perform data augmentation\n",
    "\t\t# 7. Add sample weights\n",
    "\t\t# 8. Prefetch new data before it being necessary.\n",
    "\t\treturn (data\n",
    "\t\t\t\t    .map(preprocess_sample)\n",
    "\t\t\t\t    .cache()\n",
    "\t\t\t\t    .shuffle(buffer_size)\n",
    "\t\t\t\t    .batch(batch_size)\n",
    "\t\t\t\t    .repeat()\n",
    "\t\t\t\t    .map(data_augmentation)\n",
    "\t\t\t\t    .map(compute_sample_weights)\n",
    "\t\t\t\t    .prefetch(buffer_size=tensorflow.data.AUTOTUNE))\n",
    "\telse:\n",
    "\t\t# 1. Perform preprocessing\n",
    "\t\t# 2. Generate batches\n",
    "\t\treturn (data\n",
    "\t\t\t\t\t\t.map(preprocess_sample)\n",
    "\t\t\t\t\t\t.batch(batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a24c7fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_callbacks():\n",
    "\t''' Retrieve initialized callbacks for model.fit '''\n",
    "\treturn [\n",
    "\t\tTensorBoard(\n",
    "\t\t  log_dir=os.path.join(os.getcwd(), \"unet_logs\"),\n",
    "\t\t  histogram_freq=1,\n",
    "\t\t  write_images=True\n",
    "\t\t)\n",
    "\t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03834b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probs_to_mask(probs):\n",
    "\t''' Convert Softmax output into mask. '''\n",
    "\tpred_mask = tensorflow.argmax(probs, axis=2)\n",
    "\treturn pred_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45b8d8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_plot(img_input, mask_truth, mask_probs):\n",
    "\t''' Generate a plot of input, truthy mask and probability mask. '''\n",
    "\tfig, axs = plt.subplots(1, 4)\n",
    "\tfig.set_size_inches(16, 6)\n",
    "\n",
    "\t# Plot the input image\n",
    "\taxs[0].imshow(img_input)\n",
    "\taxs[0].set_title(\"Input image\")\n",
    "\n",
    "\t# Plot the truthy mask\n",
    "\taxs[1].imshow(mask_truth)\n",
    "\taxs[1].set_title(\"True mask\")\n",
    "\n",
    "\t# Plot the predicted mask\n",
    "\tpredicted_mask = probs_to_mask(mask_probs)\n",
    "\taxs[2].imshow(predicted_mask)\n",
    "\taxs[2].set_title(\"Predicted mask\")\n",
    "\n",
    "\t# Plot the overlay\n",
    "\tconfig = configuration()\n",
    "\timg_input_resized = tensorflow.image.resize(img_input, (config.get(\"mask_width\"), config.get(\"mask_height\")))\n",
    "\taxs[3].imshow(img_input_resized)\n",
    "\taxs[3].imshow(predicted_mask, alpha=0.5)\n",
    "\taxs[3].set_title(\"Overlay\")\n",
    "\n",
    "\t# Show the plot\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee76948",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\t''' Run full training procedure. '''\n",
    "\n",
    "\t# Load config\n",
    "\tconfig = configuration()\n",
    "\tbatch_size = config.get(\"batch_size\")\n",
    "\tvalidation_sub_splits = config.get(\"validation_sub_splits\")\n",
    "\tnum_epochs = config.get(\"num_epochs\")\n",
    "\n",
    "\t# Load data\n",
    "\t(training_data, validation_data, testing_data), info = load_dataset()\n",
    "#     training_data = train_data_ip\n",
    "#     validation_data = train_data_av\n",
    "#     testing_data = test_data_ip\n",
    "\n",
    "\t# Make training data ready for model.fit and model.evaluate\n",
    "\ttrain_batches = preprocess_dataset(training_data, \"train\", info)\n",
    "\tval_batches = preprocess_dataset(validation_data, \"val\", info)\n",
    "\ttest_batches = preprocess_dataset(testing_data, \"test\", info)\n",
    "\t\n",
    "\t# Compute data-dependent variables\n",
    "\ttrain_num_samples = tensorflow.data.experimental.cardinality(training_data).numpy()\n",
    "\tval_num_samples = tensorflow.data.experimental.cardinality(validation_data).numpy()\n",
    "\tsteps_per_epoch = train_num_samples // batch_size\n",
    "\tval_steps_per_epoch = val_num_samples // batch_size // validation_sub_splits\n",
    "\n",
    "\t# Initialize model\n",
    "\tmodel = init_model(steps_per_epoch)\n",
    "\n",
    "\t# Train the model\t\n",
    "\tmodel.fit(train_batches, epochs=num_epochs, batch_size=batch_size,\\\n",
    "\t\tsteps_per_epoch=steps_per_epoch, verbose=1,\n",
    "\t\tvalidation_steps=val_steps_per_epoch, callbacks=training_callbacks(),\\\n",
    "\t\tvalidation_data=val_batches)\n",
    "\n",
    "\t# Test the model\n",
    "\tscore = model.evaluate(test_batches, verbose=0)\n",
    "\tprint(f'Test loss: {score[0]} / Test accuracy: {score[1]}')\n",
    "\n",
    "\t# Take first batch from the test images and plot them\n",
    "\tfor images, masks in test_batches.take(1):\n",
    "\n",
    "\t\t# Generate prediction for each image\n",
    "\t\tpredicted_masks = model.predict(images)\n",
    "\n",
    "\t\t# Plot each image and masks in batch\n",
    "\t\tfor index, (image, mask) in enumerate(zip(images, masks)):\n",
    "\t\t\tgenerate_plot(image, mask, predicted_masks[index])\n",
    "\t\t\tif index > 4:\n",
    "\t\t\t\tbreak\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\tmain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc67184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PrefetchDataset element_spec={'file_name': TensorSpec(shape=(), dtype=tf.string, name=None), 'image': TensorSpec(shape=(None, None, 3), dtype=tf.uint8, name=None), 'label': TensorSpec(shape=(), dtype=tf.int64, name=None), 'segmentation_mask': TensorSpec(shape=(None, None, 1), dtype=tf.uint8, name=None), 'species': TensorSpec(shape=(), dtype=tf.int64, name=None)}>\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, Features, ClassLabel\n",
    "\n",
    "(training_data, validation_data, testing_data), info = load_dataset()\n",
    "print(training_data)\n",
    "# print(train_data_ip)\n",
    "\n",
    "\n",
    "features = Features({'file_name': [img_names_train[0]], \n",
    "                     'image': [train_data_ip[0]], \n",
    "                     'label': [train_data_av[0]], \n",
    "                     'segmentation_mask': [train_data_vessel[0]]})\n",
    "ds = Dataset.from_dict({'file_name': [img_names_train[0]], \n",
    "                     'image': [train_data_ip[0]], \n",
    "                     'label': [train_data_av[0]], \n",
    "                     'segmentation_mask': [train_data_vessel[0]]})\n",
    "# ds = ds.with_format(\"tf\")\n",
    "tf_ds = ds.to_tf_dataset(columns=[\"file_name\", \"image\", \"segmentation_mask\"],\n",
    "            label_cols=[\"label\"],\n",
    "            batch_size=5,\n",
    "            shuffle=True)\n",
    "ds[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93811b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\dhyut\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3398, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\dhyut\\AppData\\Local\\Temp\\ipykernel_20412\\865252545.py\", line 3, in <cell line: 3>\n",
      "    from keras import layers\n",
      "  File \"c:\\users\\dhyut\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\keras\\__init__.py\", line 20, in <module>\n",
      "    from keras import distribute\n",
      "  File \"c:\\users\\dhyut\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\keras\\distribute\\__init__.py\", line 18, in <module>\n",
      "    from keras.distribute import sidecar_evaluator\n",
      "  File \"c:\\users\\dhyut\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\keras\\distribute\\sidecar_evaluator.py\", line 22, in <module>\n",
      "    from keras.optimizers.optimizer_experimental import (\n",
      "ModuleNotFoundError: No module named 'keras.optimizers.optimizer_experimental'; 'keras.optimizers' is not a package\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\dhyut\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 1993, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"c:\\users\\dhyut\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1118, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"c:\\users\\dhyut\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1012, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"c:\\users\\dhyut\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 865, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"c:\\users\\dhyut\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 818, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(r))\n",
      "  File \"c:\\users\\dhyut\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 736, in format_record\n",
      "    result += ''.join(_format_traceback_lines(frame_info.lines, Colors, self.has_colors, lvals))\n",
      "  File \"c:\\users\\dhyut\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"c:\\users\\dhyut\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\stack_data\\core.py\", line 699, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"c:\\users\\dhyut\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"c:\\users\\dhyut\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\stack_data\\core.py\", line 647, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"c:\\users\\dhyut\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"c:\\users\\dhyut\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\stack_data\\core.py\", line 626, in executing_piece\n",
      "    return only(\n",
      "  File \"c:\\users\\dhyut\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\executing\\executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "\n",
    "\n",
    "def get_model(img_size, num_classes):\n",
    "    inputs = keras.Input(shape=img_size + (3,))\n",
    "\n",
    "    ### [First half of the network: downsampling inputs] ###\n",
    "\n",
    "    # Entry block\n",
    "    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    previous_block_activation = x  # Set aside residual\n",
    "\n",
    "    # Blocks 1, 2, 3 are identical apart from the feature depth.\n",
    "    for filters in [64, 128, 256]:\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = layers.Conv2D(filters, 1, strides=2, padding=\"same\")(\n",
    "            previous_block_activation\n",
    "        )\n",
    "        x = layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    ### [Second half of the network: upsampling inputs] ###\n",
    "\n",
    "    for filters in [256, 128, 64, 32]:\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.UpSampling2D(2)(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = layers.UpSampling2D(2)(previous_block_activation)\n",
    "        residual = layers.Conv2D(filters, 1, padding=\"same\")(residual)\n",
    "        x = layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    # Add a per-pixel classification layer\n",
    "    outputs = layers.Conv2D(num_classes, 3, activation=\"softmax\", padding=\"same\")(x)\n",
    "\n",
    "    # Define the model\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "# Free up RAM in case the model definition cells were run multiple times\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# Build model\n",
    "model = get_model(img_size, num_classes)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c27525",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
